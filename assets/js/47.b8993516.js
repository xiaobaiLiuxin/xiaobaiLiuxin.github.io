(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{599:function(e,r,a){"use strict";a.r(r);var t=a(17),s=Object(t.a)({},(function(){var e=this,r=e.$createElement,a=e._self._c||r;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h3",{attrs:{id:"为什么使用消息队列-消息队列的优点和缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用消息队列-消息队列的优点和缺点"}},[e._v("#")]),e._v(" 为什么使用消息队列？消息队列的优点和缺点？")]),e._v(" "),a("p",[e._v("消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削锋和消息通讯四个场景。")]),e._v(" "),a("p",[a("strong",[e._v("异步处理：")]),e._v(" 将不是必须的业务逻辑，异步处理。例如注册后的邮件通知。")]),e._v(" "),a("p",[a("strong",[e._v("应用解耦：")]),e._v(" 例如："),a("a",{attrs:{href:"https://www.zhihu.com/search?q=%E8%AE%A2%E5%8D%95%E7%B3%BB%E7%BB%9F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("订单系统"),a("OutboundLink")],1),e._v("：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。")]),e._v(" "),a("p",[a("strong",[e._v("库存系统：")]),e._v(" 订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作")]),e._v(" "),a("p",[a("strong",[e._v("流量削锋：")]),e._v(" 一般在秒杀或团抢活动中使用广泛，可以控制活动的人数，可以缓解短时间内高流量压垮应用。")]),e._v(" "),a("p",[e._v("例如：用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。秒杀业务根据消息队列中的请求信息，再做后续处理。")]),e._v(" "),a("p",[a("strong",[e._v("日志处理：")])]),e._v(" "),a("p",[e._v("日志采集客户端，负责日志数据采集，定时接收写入Kafka队列；Kafka消息队列，负责日志数据的接收，存储和转发；日志处理应用：订阅并消费kafka队列中的日志数据")]),e._v(" "),a("p",[a("strong",[e._v("消息通讯：")]),e._v(" 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。")]),e._v(" "),a("p",[e._v("点对点模式（P2P）：客户端A和客户端B使用同一队列，进行消息通讯。")]),e._v(" "),a("p",[e._v("发布订阅模式（Pub/Sub）：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。")]),e._v(" "),a("p",[e._v("以上实际是消息队列的两种消息模式，点对点或发布订阅模式")]),e._v(" "),a("h4",{attrs:{id:"p2p"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#p2p"}},[e._v("#")]),e._v(" P2P")]),e._v(" "),a("p",[e._v("P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。")]),e._v(" "),a("p",[a("strong",[e._v("P2P的特点：")])]),e._v(" "),a("ol",[a("li",[e._v("每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)")]),e._v(" "),a("li",[e._v("发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列接收者在成功接收消息之后需向队列应答成功")]),e._v(" "),a("li",[e._v("如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式")]),e._v(" "),a("li",[e._v("Pub/sub包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。")])]),e._v(" "),a("h4",{attrs:{id:"pub-sub"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pub-sub"}},[e._v("#")]),e._v(" Pub/Sub")]),e._v(" "),a("p",[a("strong",[e._v("Pub/Sub的特点：")])]),e._v(" "),a("ol",[a("li",[e._v("每个消息可以有多个消费者")]),e._v(" "),a("li",[e._v("发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息为了消费消息，订阅者必须保持运行的状态")]),e._v(" "),a("li",[e._v("为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。")]),e._v(" "),a("li",[e._v("如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型\npull:客户端去消息队列拉取数据\npush:消息队列推数据到客户端")])]),e._v(" "),a("p",[e._v("**消息队列的缺点：**增加了系统的复杂度，引入了短暂不一致性问题。")]),e._v(" "),a("p",[a("strong",[e._v("保证消息队列的高可用：")]),e._v("\n保证消息队列发送消息和接收消息的接口是幂等的，那么怎么保证幂等呢？最简单的方式莫过于共享存储。")]),e._v(" "),a("h3",{attrs:{id:"如何设计一个高并发高可用系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何设计一个高并发高可用系统"}},[e._v("#")]),e._v(" 如何设计一个高并发高可用系统")]),e._v(" "),a("p",[e._v("1、尽量减少http请求，对静态资源使用"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%93%E5%AD%98&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("浏览器缓存"),a("OutboundLink")],1),e._v("，对需要传输的文件进行压缩，减少Cookie的传输\n2、使用CDN加速，即使用CDN缓存静态资源\n3、使用反向代理，缓存用户的请求\n4、使用分布式缓存，对缓存进行分布式部署\n5、为一个应用构建由多台服务器组成的集群。将并发请求分发到多台服务器\n6、使用多线程\n7、使用负载均衡进行无状态服务的失效转移\n8、对于有状态的服务，使用session复制(session同步)，session绑定(相同IP分发到相同服务器)，利用cookie将session记录在客户端，或者部署独立的session服务器\n9、根据服务和业务对服务器进行分级，如订单服务器高优先级，评论服务器低优先级\n10、在应用程序中设置服务器调用的超时时间\n11、合理使用异步调用\n12、服务降级，在网站高峰期对低优先级的服务进行关闭\n13、幂等性设计，保证多次服务重复调用和一次调用产生的结果相同\n14、保证数据的一致性\n15、做好数据备份")]),e._v(" "),a("h3",{attrs:{id:"如何进行限流"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何进行限流"}},[e._v("#")]),e._v(" 如何进行限流？")]),e._v(" "),a("p",[e._v("限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）\n一般开发高并发系统常见的限流有：限制总并发数、限制瞬时并发数、限制时间窗口内的平均速率、其他还有如限制远程接口调用速率、限制MQ的消费速率。另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流。")]),e._v(" "),a("h3",{attrs:{id:"什么是熔断-常用的熔断框架"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是熔断-常用的熔断框架"}},[e._v("#")]),e._v(" 什么是熔断？常用的熔断框架？")]),e._v(" "),a("p",[e._v("熔断：当所依赖的对象不稳定导致请求连续超时的时候，对后面的请求进行快速失败处理，同时根据一些算法去试探依赖对象的服务是否恢复\n服务降级：通过返回一些默认的数据来伪装服务，如默认评论、固定库存等。\ndubbo的mock机制支持熔断降级。")]),e._v(" "),a("h3",{attrs:{id:"如何进行系统拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何进行系统拆分"}},[e._v("#")]),e._v(" 如何进行系统拆分？")]),e._v(" "),a("p",[e._v("拆分可以分为两种：纵向和横向。纵向拆分主要从业务角度进行，根据业务分割为不同的子系统；而横向拆分侧重于技术的分层，每个层级的技术侧重点不同\n拆分原则：\n1、业务优先：在系统拆分时，我们就可以优先考虑按照"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=%E4%B8%9A%E5%8A%A1%E8%BE%B9%E7%95%8C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("业务边界"),a("OutboundLink")],1),e._v("进行切割，切割完成后再针对每个模块进行拆解\n2、系统拆分过程中包含两个非常重要的工作：拆分和测试。二者缺一不可，并且二者是并行进行的，一定要边拆分边测试。\n3、兼顾技术：系统不能为了分布式而分布式，系统拆分的代价相当昂贵\n拆分顺序：数据库拆分、处理公共数据（公共服务）、功能拆分")]),e._v(" "),a("h3",{attrs:{id:"如何分库分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何分库分表"}},[e._v("#")]),e._v(" 如何分库分表？")]),e._v(" "),a("p",[e._v("数据库拆分简单来说，就是指通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）上面以达到分散单库（主机）负载的效果。\n切分模式： 垂直（纵向）拆分、水平拆分。")]),e._v(" "),a("h4",{attrs:{id:"垂直拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#垂直拆分"}},[e._v("#")]),e._v(" 垂直拆分")]),e._v(" "),a("p",[e._v("专库专用，一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面")]),e._v(" "),a("p",[a("strong",[e._v("优点：")])]),e._v(" "),a("ol",[a("li",[e._v("拆分后业务清晰，拆分规则明确。")]),e._v(" "),a("li",[e._v("系统之间整合或扩展容易。")]),e._v(" "),a("li",[e._v("数据维护简单。")])]),e._v(" "),a("p",[a("strong",[e._v("缺点")]),e._v("：")]),e._v(" "),a("ol",[a("li",[e._v("部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。")]),e._v(" "),a("li",[e._v("受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。")]),e._v(" "),a("li",[e._v("事务处理复杂。")])]),e._v(" "),a("h4",{attrs:{id:"水平拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#水平拆分"}},[e._v("#")]),e._v(" 水平拆分")]),e._v(" "),a("p",[e._v("垂直拆分后遇到单机瓶颈，可以使用水平拆分。区别是：垂直拆分是把不同的表拆到不同库中，而水平拆分是把同一个表拆到不同的数据库中。\n水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中")]),e._v(" "),a("p",[a("strong",[e._v("优点：")])]),e._v(" "),a("ol",[a("li",[e._v("不存在单库大数据，高并发的性能瓶颈。")]),e._v(" "),a("li",[e._v("对应用透明，应用端改造较少。")]),e._v(" "),a("li",[e._v("按照合理拆分规则拆分，join操作基本避免跨库。")]),e._v(" "),a("li",[e._v("提高了系统的稳定性跟负载能力。")])]),e._v(" "),a("p",[a("strong",[e._v("缺点：")])]),e._v(" "),a("ol",[a("li",[e._v("拆分规则难以抽象。\n2. 分片事务一致性难以解决。\n3. 数据多次扩展难度跟维护量极大。\n4. 跨库join性能较差。\n拆分方案：范围、枚举、时间、取模、哈希")])]),e._v(" "),a("p",[e._v("如果两个对象的hashcode相同，它们不一定相等，如果equals相等，它们不一定相同。")]),e._v(" "),a("p",[e._v("hashmap和treemap的区别？\nTreeMap是SortedMap接口基于红黑树的实现，该类保证了映射按照升序排列关键字。HashMap是根据键的HashCode 值存储数据，取得数据的顺序是完全随机的，HashMap取值的速度更快")]),e._v(" "),a("h3",{attrs:{id:"线程池都有哪些参数-底层如何实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#线程池都有哪些参数-底层如何实现"}},[e._v("#")]),e._v(" 线程池都有哪些参数？底层如何实现？")]),e._v(" "),a("h4",{attrs:{id:"初始化4种类型的线程池"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#初始化4种类型的线程池"}},[e._v("#")]),e._v(" 初始化4种类型的线程池：")]),e._v(" "),a("p",[a("strong",[e._v("newFixedThreadPool()")])]),e._v(" "),a("blockquote",[a("p",[e._v("说明：初始化一个指定线程数的线程池，其中corePoolSize == maxiPoolSize，使用LinkedBlockingQuene作为阻塞队列\n特点：即使当线程池没有可执行任务时，也不会释放线程。")])]),e._v(" "),a("p",[a("strong",[e._v("newCachedThreadPool()")])]),e._v(" "),a("blockquote",[a("p",[e._v("说明：初始化一个可以缓存线程的线程池，默认缓存60s，线程池的线程数可达到Integer.MAX_VAL UE，即2147483647，内部使用SynchronousQueue作为阻塞队列；\n特点：在没有任务执行时，当线程的空闲时间超过keepAliveTime，会自动释放线程资源；当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销；\n因此，使用时要注意控制并发的任务数，防止因创建大量的线程导致而降低性能。")])]),e._v(" "),a("p",[a("strong",[e._v("newSingleThreadExecutor()")])]),e._v(" "),a("blockquote",[a("p",[e._v("说明：初始化只有一个线程的线程池，内部使用LinkedBlockingQueue作为阻塞队列。\n特点：如果该线程异常结束 ，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行")])]),e._v(" "),a("p",[a("strong",[e._v("newScheduledThreadPool()")])]),e._v(" "),a("blockquote",[a("p",[e._v("特定：初始化的线程池可以在指定的时间内周期性的执行所提交的任务，在实际的业务场景中可以使用该线程池定期的同步数据。")])]),e._v(" "),a("p",[e._v("总结：除了newScheduledThreadPool的内部实现特殊，其它线程池内部都是基于ThreadPoolExecutor类（Executor的子类）实现的。")]),e._v(" "),a("h4",{attrs:{id:"threadpoolexecutor的参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#threadpoolexecutor的参数"}},[e._v("#")]),e._v(" ThreadPoolExecutor的参数：")]),e._v(" "),a("p",[e._v("corePoolSize：核心线程数\nmaxPoolSize：最大线程数\nkeepAliveTime：线程存活时间（在corePore<*<maxPoolSize情况下有用）\ntimeUnit：存活时间的时间单位\nworkQueue：阻塞队列（用来保存等待被执行的任务）\nthreadFactory：线程工厂,主要用来创建线程；\nhandler：表示当拒绝处理任务时的策略，有以下四种取值")]),e._v(" "),a("h4",{attrs:{id:"线程池的状态"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#线程池的状态"}},[e._v("#")]),e._v(" 线程池的状态：")]),e._v(" "),a("p",[e._v("1、RUNNING：该状态的线程池会接收新任务，并处理阻塞队列中的任务；\n2、SHUTDOWN： 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；\n3、STOP ： 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；\n4、TIDYING ：该状态表示线程池对线程进行整理优化；\n5、TERMINATED： 即高3位为011，该状态表示线程池停止工作；")]),e._v(" "),a("h4",{attrs:{id:"向线程池提交任务有两种方式-excute和submit"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#向线程池提交任务有两种方式-excute和submit"}},[e._v("#")]),e._v(" 向线程池提交任务有两种方式：excute和submit")]),e._v(" "),a("p",[e._v("线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果阻塞队列满了，那就创建新的线程执行当前任务；直到线程池中的线程数达到maxPoolSize,这时再有任务来，只能执行reject()处理该任务；")]),e._v(" "),a("h3",{attrs:{id:"synchronized与lock的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#synchronized与lock的区别"}},[e._v("#")]),e._v(" synchronized与Lock的区别？")]),e._v(" "),a("p",[a("strong",[e._v("锁的类型：")])]),e._v(" "),a("p",[e._v("可重入锁：在执行对象中所有同步方法不用再次获得锁\n可中断锁：在等待获取锁过程中可中断\n公平锁： 按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利\n读写锁：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写")]),e._v(" "),a("p",[e._v("synchronized是Java关键字，而Lock是一个类。synchronized以获取锁的线程执行完同步代码，释放锁；线程执行发生异常，也会释放锁。而Lock在finally中必须释放锁。synchronized获取不到锁的时候会一直等待。")]),e._v(" "),a("p",[e._v("Lock则可以通过tryLock等方法尝试获得锁，不必一直等待。synchronized无法判断锁状态，Lock可以。synchronized的锁是可重入、不可中断、非公平，而Lock的锁是可重入、可判断、可公平。Lock性能强于synchronized。")]),e._v(" "),a("h3",{attrs:{id:"讲讲threadlocal"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#讲讲threadlocal"}},[e._v("#")]),e._v(" 讲讲ThreadLocal？")]),e._v(" "),a("p",[e._v("ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。\n主要是get和set方法：\n在set时，首先获得当前线程对象，通过getMap拿到线程的ThreadLocalMap，并将值设入map中，这个map是threadlocal类内部的map，key是threadlocal当前对象，value就是我们需要的值。\nget也是先取得当前线程的"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=threadlocalmap%E5%AF%B9%E8%B1%A1&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("threadlocalmap对象"),a("OutboundLink")],1),e._v("，然后将自己作为key取得内部的实际数据。\n不用了以后可以通过threadlocal的remove方法将 变量移除。")]),e._v(" "),a("h3",{attrs:{id:"class-forname和classloader的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-forname和classloader的区别"}},[e._v("#")]),e._v(" Class.forName和classloader的区别")]),e._v(" "),a("p",[e._v("class.forName()前者除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。\n而classLoader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。\nClass.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象")]),e._v(" "),a("h3",{attrs:{id:"spring的原理机制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spring的原理机制"}},[e._v("#")]),e._v(" spring的原理机制？")]),e._v(" "),a("p",[e._v("包扫描，类加载，把被注解的注入进去ioc容器。所谓的"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=ioc%E5%AE%B9%E5%99%A8&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("ioc容器"),a("OutboundLink")],1),e._v("就是一个map，key是类，value是类的实例。基本上dao service controller都是单利的。扫描类中的field，给被@Autowierd注解的field赋值。\n通过application context来启动spring框架，然后开始DI，根据xml配置文件里面的bean配置或者扫描代码，根据annotation，实例化一堆组件对象，然后存入内存，类似于：my组建 组件1 = new my组建()。然后再根据配置文件或者扫描源码，找到要注入的（也就是加了Autowire的）引用，建立起这个引用对象和刚刚实例化的对象间的关系，例如有@Autowierd my组建 my组建 ,就是类似：my组建 = 组建1.\nspring容器是Spring的核心，该 容器负责管理spring中的java组件，ApplicationContext容器容器会自动预初始化所有Bean实例，\n默认会实例化所有的singleton Bean\n依赖注入一般有2中方式：\n设置注入：IoC容器使用属性的setter方式注入被依赖的实例。"),a("property",{ref:"",attrs:{name:""}},[e._v("\n构造注入：IoC容器使用构造器来注入被依赖的实例。"),a("constructor-arg",{ref:""})],1)],1),e._v(" "),a("h3",{attrs:{id:"spring的两种代理jdk和cglib的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spring的两种代理jdk和cglib的区别"}},[e._v("#")]),e._v(" Spring的两种代理JDK和CGLIB的区别？")]),e._v(" "),a("p",[e._v("JDK动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。")]),e._v(" "),a("p",[e._v("使用JDK动态代理，目标类必须实现的某个接口，如果某个类没有实现接口则不能生成代理对象；CGLib 必须依赖于CGLib的类库，Cglib原理是针对目标类生成一个子类，覆盖其中的所有方法，所以目标类和方法不能声明为final类型")]),e._v(" "),a("p",[e._v("从执行效率上看，Cglib动态代理效率较高")]),e._v(" "),a("h3",{attrs:{id:"mysql索引的数据结构-b-树和b树-b-树是b树的增强版。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql索引的数据结构-b-树和b树-b-树是b树的增强版。"}},[e._v("#")]),e._v(" mysql索引的数据结构：B+树和B树，B+树是B树的增强版。")]),e._v(" "),a("p",[e._v("两种树的区别：\nB树的特性：\n1.关键字集合分布在整颗树中；\n2.任何一个关键字出现且只出现在一个结点中；\n3.搜索有可能在非叶子结点结束；\n4.其搜索性能等价于在关键字全集内做一次二分查找，最高时间复杂度为Olog2N；\n5.自动层次控制；\nB_TREE的查找\n在B_TREE上查找x，现将x的关键字与根结点的n个关键字di逐个比较，然后做如下处理：\n若x.key==di，则查找成功返回；\n若x.key<d1，则沿着指针c0所指的子树继续查找；\n若di<x.key<d(i+1)，则沿着指针ci所指的子树继续查找；\n若x.key>dn，则沿着指针cn所指的子树继续查找。\n所以，在B树中，若我需要读取key为“10”与“12”的数据，需要先定位到10，再重新从根往下寻找12。如果需要查询的数据量一多，B树性能就很糟糕。还有一点，就是B树的每个节点都包含key及其value数据，这样的话，我每次读取叶子节点的数据时，在经过路径上的非叶子节点也会被读出，但实际上这部分数据我是不需要的，这样又占用了没有必要的内存空间。所以B+树对B树进行了优化。")]),e._v(" "),a("h3",{attrs:{id:"b-tree的性质"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#b-tree的性质"}},[e._v("#")]),e._v(" B＋tree的性质：")]),e._v(" "),a("p",[e._v("1.n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。\n2.所有的"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=%E5%8F%B6%E5%AD%90%E7%BB%93%E7%82%B9&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("叶子结点"),a("OutboundLink")],1),e._v("中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接指针。\n3.所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。\nB树和B+树的特点是每个节点可以有在预定范围内可变数目的子节点数，因此不需要像其他的自平衡二叉树一样经常重新平衡。\nB+树不同于B-树的地方：\nB+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。\nB+树的叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。")]),e._v(" "),a("h3",{attrs:{id:"redis持久化和主从复制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化和主从复制"}},[e._v("#")]),e._v(" Redis持久化和主从复制")]),e._v(" "),a("h4",{attrs:{id:"持久化方式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#持久化方式"}},[e._v("#")]),e._v(" 持久化方式：")]),e._v(" "),a("p",[e._v("RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。")]),e._v(" "),a("p",[e._v("AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。")]),e._v(" "),a("p",[e._v("Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。")]),e._v(" "),a("p",[e._v("你甚至可以关闭持久化功能，让数据只在服务器运行时存在。")]),e._v(" "),a("h5",{attrs:{id:"rdb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rdb"}},[e._v("#")]),e._v(" RDB")]),e._v(" "),a("p",[e._v("在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 snapshot 快照，它恢复时就是将快照文件直接读到内存里。")]),e._v(" "),a("p",[e._v("Redis 会单独的创建(fork) 一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程结束了，再用这个临时文件替换上次持久化还的文件。整个过程总，主进程是不进行任何 IO 操作，这就确保了极高的性能，如果需要进行大规模的数据恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方法要比 AOF 方式更加的高效。RDB 的缺点是最后一次持久化后的数据可能丢失。")]),e._v(" "),a("p",[e._v("Fork的作用是复制一个与当前进程一样的进程，新进程的所有数据(变量、环境变量、"),a("a",{attrs:{href:"https://www.zhihu.com/search?q=%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("程序计数器"),a("OutboundLink")],1),e._v("等)数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程")]),e._v(" "),a("p",[e._v("隐患：若当前的进程的数据量庞大，那么 fork 之后数据量*2,此时就会造成服务器压力大，运行性能降低。")]),e._v(" "),a("p",[e._v("RDB 保存的是 "),a("a",{attrs:{href:"https://www.zhihu.com/search?q=dump.rdb&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1828490473%7D",target:"_blank",rel:"noopener noreferrer"}},[e._v("dump.rdb"),a("OutboundLink")],1),e._v(" 文件")]),e._v(" "),a("h5",{attrs:{id:"aof-append-only-file"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aof-append-only-file"}},[e._v("#")]),e._v(" AOF(Append Only File)")]),e._v(" "),a("p",[e._v("以日志的形式俩记录每个写操作，将 redis 执行过的所有写指令记录下来(读操作不记录)。只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次一完成数据恢复工作。")]),e._v(" "),a("h4",{attrs:{id:"主从复制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#主从复制"}},[e._v("#")]),e._v(" 主从复制")]),e._v(" "),a("p",[e._v("该功能可以让从服务器(slave server)成为主服务器(master server)的精确复制品。\nRedis 使用异步复制。 从 Redis 2.8 开始， 从服务器会以每秒一次的频率向主服务器报告复制流（replication stream）的处理进度。\n一个主服务器可以有多个从服务器。\n不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个图状结构。\n复制功能不会阻塞主服务器： 即使有一个或多个从服务器正在进行初次同步， 主服务器也可以继续处理命令请求。\n复制功能也不会阻塞从服务器： 只要在 redis.conf 文件中进行了相应的设置， 即使从服务器正在进行初次同步， 服务器也可以使用旧版本的数据集来处理命令查询。")])])}),[],!1,null,null,null);r.default=s.exports}}]);